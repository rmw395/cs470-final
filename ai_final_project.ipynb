{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset\n",
        "\n",
        "1. load csv file (panda, numpy)\n",
        "2. split dataset. Example code:()\n",
        "   ```\n",
        "   random.shuffle(data) # change if you are using pandas dataframe\n",
        "   training = data[:int(len(data)*0.8)]\n",
        "   test = data[int(len(data)*0.8):]\n",
        "\n",
        "   fold5 = KFold(5) # https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html\n",
        "   for train_idx, val_idx in fold5.split(training):\n",
        "      sub_val = training[val_idx]\n",
        "      sub_train = training[train_idx]\n",
        "      clf = model(sub_train, sub_val, ...) # training the model, and evaluate it on validation dataset\n",
        "      performance(clf, test) # test the model on test dataset\n",
        "   ```"
      ],
      "metadata": {
        "id": "uxgBX0YXu1du"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Naive bayes\n",
        "\n",
        "1. model learning:\n",
        "\n",
        "   Note:\n",
        "\n",
        "   features: remove attributes that is not related to word (the last four attributes)\n",
        "\n",
        "   labels: the last column\n",
        "\n",
        "   count P(c) -> how many samples are positive, and how many are negtive\n",
        "\n",
        "   if freq_word>0, then this word exists. You could use this to calculate P(a|c) -> for each class, what is the prob of each word\n",
        "\n",
        "   remember to use laplace smoothing.\n",
        "\n",
        "2. model evaluation (on val dataset -> performance(model, val)):\n",
        "   \n",
        "   for each new sample, $\\prod{P(a|c)}P(c)$ if word is in the email(freq_word > 0); and find the maximum class\n",
        "   \n",
        "\n",
        "   "
      ],
      "metadata": {
        "id": "FXyRfd35yRPd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# KNN\n",
        "1. model learning: None\n",
        "\n",
        "2. model evaluation(on val dataset): You could use each row(exclude the last column) as the feature of the email. You do not have to recalcuate the freqency.\n",
        "\n",
        "   ```\n",
        "   Note:\n",
        "   parallel programing\n",
        "   numpy.cos() to calcuate the similarity\n",
        "   ```"
      ],
      "metadata": {
        "id": "5jRvHTlW0DYA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LR\n",
        "\n",
        "1. model learning: You could use each row(exclude the last column) as the feature of the email. You do not have to recalcuate the freqency.\n",
        "    \n",
        "    $y = sigmoid(MX)$\n",
        "\n",
        "step 1: add one more column (all value is 1) in X -> X' = np.c_[np.ones((len(X), 1)), X]\n",
        "\n",
        "step 2:vector M = np.random.randn(len(X[0])+1, 1);\n",
        "\n",
        "key formula for step 3 (Note: n is the size of the TRAINING dataset; $cdot$ is dot production ):\n",
        "\n",
        "1. $pred_y = sigmoid(M\\cdot X')$\n",
        "\n",
        "2. $loss = -\\sum(y\\cdot log(pred_y)+(1-y)\\cdot log(1-pred_y))/n$\n",
        "\n",
        "3. $gm=X'\\cdot (pred_y - y)*2/n$\n",
        "\n",
        "Step 3 example code:\n",
        "   ```\n",
        "   #Step 3: performing gradient descent on whole dataset:\n",
        "   best_model = M\n",
        "   best_performace = 0\n",
        "   for i in range(epoch):\n",
        "     pred_y = ...\n",
        "     gm = ...\n",
        "     _p = performace(model, val)\n",
        "     if _p > best_performance:\n",
        "        best_model = M\n",
        "        best_performance = _p\n",
        "     M = M - learning_rate*gm\n",
        "   ```\n",
        "\n",
        "2. model evaluation(on val dataset):\n",
        "  \n",
        "   calculate pred_y, if more than 0.5, then the predicted label is 1."
      ],
      "metadata": {
        "id": "OUzUupva0Fxw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Evaluation\n",
        "\n",
        "https://scikit-learn.org/stable/modules/model_evaluation.html"
      ],
      "metadata": {
        "id": "mAssSW_I0GvA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def performance(model, data):\n",
        "  print(\"result:\")\n",
        "  return result"
      ],
      "metadata": {
        "id": "e0MQ0eo0MnmB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}