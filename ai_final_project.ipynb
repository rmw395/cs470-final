{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAssSW_I0GvA"
      },
      "source": [
        "# Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import sklearn as skl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {},
      "outputs": [],
      "source": [
        "def loadData():\n",
        "    # load data\n",
        "    spam_data = pd.read_csv(\"spambase.csv\")\n",
        "\n",
        "    # shuffle data\n",
        "    spam_data = spam_data.sample(frac=1)\n",
        "\n",
        "    # first 80% is training, last 20% is test\n",
        "    training = spam_data[:int(len(spam_data)*0.8)]\n",
        "    test = spam_data[int(len(spam_data)*0.8):]\n",
        "\n",
        "    # get kfold\n",
        "    kfold = skl.model_selection.KFold(5)\n",
        "\n",
        "    # loop over split values\n",
        "    for train_index, valid_index in kfold.split(training):\n",
        "        # get validation and training datasets\n",
        "        sub_validation = training.iloc[valid_index]\n",
        "        sub_training = training.iloc[train_index]\n",
        "\n",
        "    return sub_validation, sub_training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {},
      "outputs": [],
      "source": [
        "def naiveBayes(training, test):\n",
        "\n",
        "    pSpam = dict()\n",
        "    pNot = dict()\n",
        "\n",
        "    # loop over all columns (except the last 5)\n",
        "    for col in range (54):\n",
        "        # reset counts\n",
        "        wordCount = 0\n",
        "        spamCount = 0\n",
        "        notCount = 0\n",
        "        # loop over all rows\n",
        "        for row in training.iterrows(): # how many rows ?\n",
        "            # if word is in the row\n",
        "            if training[row, col] > 0:\n",
        "                # update word count\n",
        "                wordCount = wordCount + 1\n",
        "                # if it's spam, add to spam count\n",
        "                if training[row, 57] == 1:\n",
        "                    spamCount = spamCount + 1\n",
        "                # else, add to not spam count\n",
        "                else:\n",
        "                    notCount = notCount + 1\n",
        "        # after looping over all rows\n",
        "        # do some division. or whatever\n",
        "        # add to dicts\n",
        "        pSpam[col] = spamCount / wordCount\n",
        "        pNot[col] = notCount / wordCount\n",
        "    # end dataset loop\n",
        "\n",
        "    # calculate overall probability that something is spam\n",
        "\n",
        "    totalSpam = 0\n",
        "    totalNot = 0\n",
        "\n",
        "    # loop over the rows, count how many are spam and how many aren't\n",
        "    # do some division or whatver\n",
        "    for row in training.iterrows():\n",
        "        if training[row, 57] == 1:\n",
        "            totalSpam = totalSpam + 1\n",
        "        else:\n",
        "            totalNot = totalNot + 1\n",
        "\n",
        "    prob = dict()\n",
        "\n",
        "    # for each email in test\n",
        "    for row in training.iterrows():\n",
        "        emailSpam = totalSpam\n",
        "        emailNot = totalNot\n",
        "\n",
        "        # for each word...\n",
        "        for col in range(54):\n",
        "            # if it has the word\n",
        "            if training[row, col] > 0:\n",
        "                # multiply probability that word = spam by probability of spam\n",
        "                emailSpam = emailSpam * pSpam[col]\n",
        "                # multiply probability that word != spam by probability of not spam\n",
        "                emailNot = emailNot * pNot[col]\n",
        "        # whichever probability is higher. say it is that.\n",
        "        if emailSpam > emailNot:\n",
        "            prob[col] = 1\n",
        "        else:\n",
        "            prob[col] = 0\n",
        "\n",
        "    return prob\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {},
      "outputs": [],
      "source": [
        "def knn(training, test):\n",
        "\n",
        "    distances = skl.metrics.pairwise_distances(training, test)\n",
        "\n",
        "    pred = dict()\n",
        "\n",
        "    for row in range(len(distances)): # that probably doesn't work but yknow\n",
        "        # fill array with the first val\n",
        "        close = list()\n",
        "        closest = distances[row][0]\n",
        "        # find closest rows...\n",
        "        for col in range(len(distances[row])):\n",
        "            if distances[row][col] <= closest:\n",
        "                closest = distances[row][col]\n",
        "                close.append(col)\n",
        "        # just get the 5 closest\n",
        "        # i am assuming that there are at least 5 that are in the list\n",
        "        # there probably are. so it's fine.\n",
        "        close = close[-5:]\n",
        "\n",
        "        spam = 0\n",
        "        for i in range(5):\n",
        "            spam = spam + test[i, 57]\n",
        "        \n",
        "        if spam > 5 - spam:\n",
        "            pred[row] = 1\n",
        "        else:\n",
        "            pred[row] = 0\n",
        "    \n",
        "    return pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {},
      "outputs": [],
      "source": [
        "def lr(data):\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "final actual real things"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "val, train = loadData()\n",
        "naiveBayes(train, val)\n",
        "knn(train, val)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
